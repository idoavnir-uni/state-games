{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RetNet State Extraction - Testing and Verification\n",
        "\n",
        "This notebook tests the state extraction mechanism for RetNet and compares different extraction methods.\n",
        "\n",
        "**Goals:**\n",
        "1. Load the RetNet-2.7B model\n",
        "2. Compare 3 extraction methods:\n",
        "   - `extract_states` - Final state only (single forward pass)\n",
        "   - `extract_states_incremental` - All positions (O(N²) - slow)\n",
        "   - `extract_incremental_states_single_pass` - All positions (O(N) - efficient)\n",
        "3. Verify correctness by comparing results\n",
        "4. Measure and compare performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running in Google Colab\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running locally\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    if not os.path.exists('state-games'):\n",
        "        print(\"Cloning repository...\")\n",
        "        !git clone https://github.com/idoavnir-uni/state-games.git\n",
        "        print(\"Repository cloned!\")\n",
        "    \n",
        "    os.chdir('state-games')\n",
        "    print(f\"Current directory: {os.getcwd()}\")\n",
        "    \n",
        "    print(\"\\nInstalling dependencies...\")\n",
        "    %pip install -q torch>=2.0.0 transformers>=4.30.0 huggingface_hub numpy pandas matplotlib einops h5py scikit-learn\n",
        "    \n",
        "    print(\"\\nInstalling Flash Linear Attention library...\")\n",
        "    %pip install -q git+https://github.com/sustcsonglin/flash-linear-attention.git\n",
        "    \n",
        "    print(\"\\nDependencies installed!\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    sys.path.insert(0, '/content/state-games')\n",
        "else:\n",
        "    sys.path.insert(0, os.path.abspath('..'))\n",
        "\n",
        "from models.load_retnet import load_retnet_model, get_model_config, print_model_structure\n",
        "from models.state_extractor import RetNetStateExtractor, save_states_to_file, load_states_from_file\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Model and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if CUDA is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if device == \"cpu\":\n",
        "    print(\"WARNING: Running on CPU. This will be very slow for 2.7B model.\")\n",
        "    print(\"Consider running on a GPU or using a smaller model for testing.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the model\n",
        "print(\"Loading RetNet-2.7B model...\")\n",
        "model, tokenizer = load_retnet_model(\n",
        "    model_name=\"fla-hub/retnet-2.7B-100B\",\n",
        "    device=device,\n",
        "    torch_dtype=torch.bfloat16\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get model configuration\n",
        "config = get_model_config(model)\n",
        "\n",
        "print(\"\\n=== Key Configuration ===\")\n",
        "print(f\"Number of layers: {config.get('num_layers', 'Unknown')}\")\n",
        "print(f\"Number of heads: {config.get('num_heads', 'Unknown')}\")\n",
        "print(f\"Hidden size: {config.get('hidden_size', 'Unknown')}\")\n",
        "print(f\"Vocabulary size: {config.get('vocab_size', 'Unknown')}\")\n",
        "print(f\"Max sequence length: {config.get('max_seq_len', 'Unknown')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print model structure to understand layer organization\n",
        "print_model_structure(model, max_depth=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initialize State Extractor and Prepare Test Input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extractor = RetNetStateExtractor(model, verbose=True)\n",
        "\n",
        "# Prepare test input\n",
        "test_text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "print(f\"Input text: '{test_text}'\")\n",
        "\n",
        "inputs = tokenizer(test_text, return_tensors=\"pt\")\n",
        "input_ids = inputs.input_ids.to(device)\n",
        "\n",
        "print(f\"Token IDs shape: {input_ids.shape}\")\n",
        "print(f\"Tokens: {tokenizer.convert_ids_to_tokens(input_ids[0])}\")\n",
        "print(f\"\\nState extractor ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Debug: Inspect cache structure directly\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids, use_cache=True)\n",
        "\n",
        "print(f\"Outputs type: {type(outputs)}\")\n",
        "print(f\"past_key_values type: {type(outputs.past_key_values)}\")\n",
        "print(f\"Number of layers: {len(outputs.past_key_values)}\")\n",
        "\n",
        "print(f\"\\nFirst layer cache:\")\n",
        "first_layer = outputs.past_key_values[0]\n",
        "print(f\"Type: {type(first_layer)}\")\n",
        "print(f\"Keys: {first_layer.keys() if isinstance(first_layer, dict) else 'Not a dict'}\")\n",
        "\n",
        "if \"recurrent_state\" in first_layer:\n",
        "    print(f\"\\nrecurrent_state shape: {first_layer['recurrent_state'].shape}\")\n",
        "    print(f\"recurrent_state dtype: {first_layer['recurrent_state'].dtype}\")\n",
        "    \n",
        "print(f\"\\nAll available keys in first layer:\")\n",
        "for key, value in first_layer.items():\n",
        "    if isinstance(value, torch.Tensor):\n",
        "        print(f\"  {key}: shape={value.shape}, dtype={value.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Compare Extraction Methods\n",
        "\n",
        "We compare three extraction methods:\n",
        "1. **`extract_states`** - Gets only the final state (single forward pass)\n",
        "2. **`extract_states_incremental`** - Gets all intermediate states (O(N²) - runs full prefix for each position)\n",
        "3. **`extract_incremental_states_single_pass`** - Gets all intermediate states (O(N) - efficient incremental processing)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 1: extract_final_states - Final state only (single forward pass)\n",
        "print(\"=\" * 60)\n",
        "print(\"METHOD 1: extract_final_states (final state only)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "start_time = time.time()\n",
        "final_states = extractor.extract_final_states(input_ids)\n",
        "time_method1 = time.time() - start_time\n",
        "\n",
        "print(f\"\\nTime: {time_method1:.4f}s\")\n",
        "print(f\"Number of layers: {len(final_states)}\")\n",
        "if final_states:\n",
        "    first_layer_state = final_states[0]\n",
        "    print(f\"State shape per layer: {first_layer_state.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 2: extract_incremental_states_dumb_rerunning - All positions (O(N²) - slow)\n",
        "print(\"=\" * 60)\n",
        "print(\"METHOD 2: extract_incremental_states_dumb_rerunning (O(N²) - slow)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "start_time = time.time()\n",
        "incremental_states = extractor.extract_incremental_states_dumb_rerunning(input_ids)\n",
        "time_method2 = time.time() - start_time\n",
        "\n",
        "print(f\"\\nTime: {time_method2:.4f}s\")\n",
        "print(f\"Number of positions: {len(incremental_states)}\")\n",
        "first_pos_states = incremental_states[1]\n",
        "print(f\"Number of layers per position: {len(first_pos_states)}\")\n",
        "print(f\"State shape at each position: {first_pos_states[0].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 3: extract_incremental_states_single_pass - All positions (O(N) - efficient)\n",
        "print(\"=\" * 60)\n",
        "print(\"METHOD 3: extract_incremental_states_single_pass (O(N) - efficient)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "start_time = time.time()\n",
        "single_pass_states = extractor.extract_incremental_states_single_pass(input_ids)\n",
        "time_method3 = time.time() - start_time\n",
        "\n",
        "print(f\"\\nTime: {time_method3:.4f}s\")\n",
        "print(f\"Number of positions: {len(single_pass_states)}\")\n",
        "first_pos_states_sp = single_pass_states[1]\n",
        "print(f\"Number of layers per position: {len(first_pos_states_sp)}\")\n",
        "print(f\"State shape at each position: {first_pos_states_sp[0].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Compare Results and Verify Correctness\n",
        "\n",
        "This section verifies that the efficient method produces the same results as the slow method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare timing\n",
        "print(\"=\" * 60)\n",
        "print(\"TIMING COMPARISON\")\n",
        "print(\"=\" * 60)\n",
        "seq_len = input_ids.shape[1]\n",
        "print(f\"\\nSequence length: {seq_len} tokens\")\n",
        "print(f\"\\nMethod 1 (final state only):    {time_method1:.4f}s\")\n",
        "print(f\"Method 2 (incremental, O(N²)):  {time_method2:.4f}s\")\n",
        "print(f\"Method 3 (single-pass, O(N)):   {time_method3:.4f}s\")\n",
        "print(f\"\\nSpeedup (Method 3 vs Method 2): {time_method2 / time_method3:.2f}x\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify correctness: compare final states from all methods\n",
        "print(\"=\" * 60)\n",
        "print(\"CORRECTNESS VERIFICATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "seq_len = input_ids.shape[1]\n",
        "\n",
        "# Compare final state from method 1 with last position from method 2 and 3\n",
        "print(\"\\n1. Comparing final state (Method 1) vs last position (Method 2):\")\n",
        "all_match_1_vs_2 = True\n",
        "for layer_idx in final_states.keys():\n",
        "    state_m1 = final_states[layer_idx]\n",
        "    state_m2 = incremental_states[seq_len][layer_idx]\n",
        "    is_close = torch.allclose(state_m1, state_m2, rtol=1e-4, atol=1e-6)\n",
        "    if not is_close:\n",
        "        all_match_1_vs_2 = False\n",
        "        max_diff = (state_m1 - state_m2).abs().max().item()\n",
        "        print(f\"   Layer {layer_idx}: MISMATCH (max diff: {max_diff:.2e})\")\n",
        "print(f\"   All layers match: {all_match_1_vs_2}\")\n",
        "\n",
        "print(\"\\n2. Comparing final state (Method 1) vs last position (Method 3):\")\n",
        "all_match_1_vs_3 = True\n",
        "for layer_idx in final_states.keys():\n",
        "    state_m1 = final_states[layer_idx]\n",
        "    state_m3 = single_pass_states[seq_len][layer_idx]\n",
        "    is_close = torch.allclose(state_m1, state_m3, rtol=1e-4, atol=1e-6)\n",
        "    if not is_close:\n",
        "        all_match_1_vs_3 = False\n",
        "        max_diff = (state_m1 - state_m3).abs().max().item()\n",
        "        print(f\"   Layer {layer_idx}: MISMATCH (max diff: {max_diff:.2e})\")\n",
        "print(f\"   All layers match: {all_match_1_vs_3}\")\n",
        "\n",
        "print(\"\\n3. Comparing all positions (Method 2 vs Method 3):\")\n",
        "all_match_2_vs_3 = True\n",
        "mismatches = []\n",
        "for pos in incremental_states.keys():\n",
        "    for layer_idx in incremental_states[pos].keys():\n",
        "        state_m2 = incremental_states[pos][layer_idx]\n",
        "        state_m3 = single_pass_states[pos][layer_idx]\n",
        "        is_close = torch.allclose(state_m2, state_m3, rtol=1e-4, atol=1e-6)\n",
        "        if not is_close:\n",
        "            all_match_2_vs_3 = False\n",
        "            max_diff = (state_m2 - state_m3).abs().max().item()\n",
        "            mismatches.append((pos, layer_idx, max_diff))\n",
        "\n",
        "if mismatches:\n",
        "    print(f\"   Found {len(mismatches)} mismatches:\")\n",
        "    for pos, layer_idx, diff in mismatches[:5]:\n",
        "        print(f\"     Position {pos}, Layer {layer_idx}: max diff = {diff:.2e}\")\n",
        "else:\n",
        "    print(f\"   All positions match: {all_match_2_vs_3}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize timing comparison\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "methods = ['Method 1\\n(final only)', 'Method 2\\n(incremental O(N²))', 'Method 3\\n(single-pass O(N))']\n",
        "times = [time_method1, time_method2, time_method3]\n",
        "colors = ['#2ecc71', '#e74c3c', '#3498db']\n",
        "\n",
        "bars = ax.bar(methods, times, color=colors, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "for bar, t in zip(bars, times):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
        "            f'{t:.3f}s', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "ax.set_ylabel('Time (seconds)', fontsize=12)\n",
        "ax.set_title(f'State Extraction Methods Comparison\\n(Sequence length: {seq_len} tokens)', fontsize=14)\n",
        "ax.set_ylim(0, max(times) * 1.2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"- For final state only: Use Method 1 (fastest)\")\n",
        "print(f\"- For all intermediate states: Use Method 3 (single-pass)\")\n",
        "print(f\"- Method 3 is {time_method2/time_method3:.1f}x faster than Method 2 for this sequence\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
