{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RetNet State Extraction - Testing and Verification\n",
        "\n",
        "This notebook tests the state extraction mechanism for RetNet and verifies that retention states are correctly captured from all layers.\n",
        "\n",
        "**Goals:**\n",
        "1. Load the RetNet-2.7B model\n",
        "2. Extract retention states using forward hooks\n",
        "3. Verify state shapes and dimensions\n",
        "4. Test state behavior on different inputs\n",
        "5. Analyze state properties\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running in Google Colab\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running locally\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    if not os.path.exists('state-games'):\n",
        "        print(\"Cloning repository...\")\n",
        "        !git clone https://github.com/idoavnir-uni/state-games.git\n",
        "        print(\"Repository cloned!\")\n",
        "    \n",
        "    os.chdir('state-games')\n",
        "    print(f\"Current directory: {os.getcwd()}\")\n",
        "    \n",
        "    print(\"\\nInstalling dependencies...\")\n",
        "    %pip install -q torch>=2.0.0 transformers>=4.30.0 huggingface_hub numpy pandas matplotlib einops h5py scikit-learn\n",
        "    \n",
        "    print(\"\\nInstalling Flash Linear Attention library...\")\n",
        "    %pip install -q git+https://github.com/sustcsonglin/flash-linear-attention.git\n",
        "    \n",
        "    print(\"\\nDependencies installed!\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    sys.path.insert(0, '/content/state-games')\n",
        "else:\n",
        "    sys.path.insert(0, os.path.abspath('..'))\n",
        "\n",
        "from models.load_retnet import load_retnet_model, get_model_config, print_model_structure\n",
        "from models.state_extractor import RetNetStateExtractor, save_states_to_file, load_states_from_file\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Model and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if CUDA is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if device == \"cpu\":\n",
        "    print(\"WARNING: Running on CPU. This will be very slow for 2.7B model.\")\n",
        "    print(\"Consider running on a GPU or using a smaller model for testing.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the model\n",
        "print(\"Loading RetNet-2.7B model...\")\n",
        "model, tokenizer = load_retnet_model(\n",
        "    model_name=\"fla-hub/retnet-2.7B-100B\",\n",
        "    device=device,\n",
        "    torch_dtype=torch.bfloat16\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get model configuration\n",
        "config = get_model_config(model)\n",
        "\n",
        "print(\"\\n=== Key Configuration ===\")\n",
        "print(f\"Number of layers: {config.get('num_layers', 'Unknown')}\")\n",
        "print(f\"Number of heads: {config.get('num_heads', 'Unknown')}\")\n",
        "print(f\"Hidden size: {config.get('hidden_size', 'Unknown')}\")\n",
        "print(f\"Vocabulary size: {config.get('vocab_size', 'Unknown')}\")\n",
        "print(f\"Max sequence length: {config.get('max_seq_len', 'Unknown')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print model structure to understand layer organization\n",
        "print_model_structure(model, max_depth=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initialize State Extractor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extractor = RetNetStateExtractor(model, verbose=True)\n",
        "\n",
        "print(\"\\nState extractor ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Extract States on Sample Input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with a simple sentence\n",
        "test_text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "print(f\"Input text: '{test_text}'\")\n",
        "print(f\"Input length: {len(test_text)} characters\")\n",
        "\n",
        "# Tokenize\n",
        "inputs = tokenizer(test_text, return_tensors=\"pt\")\n",
        "input_ids = inputs.input_ids.to(device)\n",
        "\n",
        "print(f\"Token IDs shape: {input_ids.shape}\")\n",
        "print(f\"Tokens: {tokenizer.convert_ids_to_tokens(input_ids[0])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract states\n",
        "print(\"\\nExtracting retention states...\")\n",
        "states = extractor.extract_states(input_ids)\n",
        "\n",
        "print(f\"\\nExtracted states from {len(states)} layers\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Verify State Shapes and Properties\n",
        "\n",
        "This section verifies that the extracted states have the expected dimensions and properties.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display state shapes for all layers\n",
        "print(\"\\n=== State Shapes ===\")\n",
        "for layer_idx in sorted(states.keys()):\n",
        "    state = states[layer_idx]\n",
        "    print(f\"Layer {layer_idx:2d}: shape={state.shape}, dtype={state.dtype}, device={state.device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STATE EXTRACTION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if len(states) > 0:\n",
        "    print(f\"✓ Successfully extracted states from {len(states)} layers\")\n",
        "    first_state = states[min(states.keys())]\n",
        "    print(f\"✓ State shape: {first_state.shape}\")\n",
        "    print(f\"✓ State dtype: {first_state.dtype}\")\n",
        "    print(\"\\nPhase 1 Complete! State extraction is working.\")\n",
        "    print(\"\\nNext: Create associative recall dataset and train probes.\")\n",
        "else:\n",
        "    print(\"✗ No states extracted - check hook registration\")\n",
        "\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
