{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RetNet State Extraction - Testing and Verification\n",
        "\n",
        "This notebook tests the state extraction mechanism for RetNet and verifies that retention states are correctly captured from all layers.\n",
        "\n",
        "**Goals:**\n",
        "1. Load the RetNet-2.7B model\n",
        "2. Extract retention states using forward hooks\n",
        "3. Verify state shapes and dimensions\n",
        "4. Test state behavior on different inputs\n",
        "5. Analyze state properties\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running in Google Colab\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running locally\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    if not os.path.exists('state-games'):\n",
        "        print(\"Cloning repository...\")\n",
        "        !git clone https://github.com/idoavnir-uni/state-games.git\n",
        "        print(\"Repository cloned!\")\n",
        "    \n",
        "    os.chdir('state-games')\n",
        "    print(f\"Current directory: {os.getcwd()}\")\n",
        "    \n",
        "    print(\"\\nInstalling dependencies...\")\n",
        "    %pip install -q torch>=2.0.0 transformers>=4.30.0 huggingface_hub numpy pandas matplotlib einops h5py scikit-learn\n",
        "    \n",
        "    print(\"\\nInstalling Flash Linear Attention library...\")\n",
        "    %pip install -q git+https://github.com/sustcsonglin/flash-linear-attention.git\n",
        "    \n",
        "    print(\"\\nDependencies installed!\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    sys.path.insert(0, '/content/state-games')\n",
        "else:\n",
        "    sys.path.insert(0, os.path.abspath('..'))\n",
        "\n",
        "from models.load_retnet import load_retnet_model, get_model_config, print_model_structure\n",
        "from models.state_extractor import RetNetStateExtractor, save_states_to_file, load_states_from_file\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Model and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if CUDA is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if device == \"cpu\":\n",
        "    print(\"WARNING: Running on CPU. This will be very slow for 2.7B model.\")\n",
        "    print(\"Consider running on a GPU or using a smaller model for testing.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the model\n",
        "print(\"Loading RetNet-2.7B model...\")\n",
        "model, tokenizer = load_retnet_model(\n",
        "    model_name=\"fla-hub/retnet-2.7B-100B\",\n",
        "    device=device,\n",
        "    torch_dtype=torch.bfloat16\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get model configuration\n",
        "config = get_model_config(model)\n",
        "\n",
        "print(\"\\n=== Key Configuration ===\")\n",
        "print(f\"Number of layers: {config.get('num_layers', 'Unknown')}\")\n",
        "print(f\"Number of heads: {config.get('num_heads', 'Unknown')}\")\n",
        "print(f\"Hidden size: {config.get('hidden_size', 'Unknown')}\")\n",
        "print(f\"Vocabulary size: {config.get('vocab_size', 'Unknown')}\")\n",
        "print(f\"Max sequence length: {config.get('max_seq_len', 'Unknown')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print model structure to understand layer organization\n",
        "print_model_structure(model, max_depth=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initialize State Extractor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extractor = RetNetStateExtractor(model, verbose=True)\n",
        "\n",
        "print(\"\\nState extractor ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Debug: Inspect cache structure directly\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids, use_cache=True)\n",
        "\n",
        "print(f\"Outputs type: {type(outputs)}\")\n",
        "print(f\"past_key_values type: {type(outputs.past_key_values)}\")\n",
        "print(f\"Number of layers: {len(outputs.past_key_values)}\")\n",
        "\n",
        "print(f\"\\nFirst layer cache:\")\n",
        "first_layer = outputs.past_key_values[0]\n",
        "print(f\"Type: {type(first_layer)}\")\n",
        "print(f\"Keys: {first_layer.keys() if isinstance(first_layer, dict) else 'Not a dict'}\")\n",
        "\n",
        "if \"recurrent_state\" in first_layer:\n",
        "    print(f\"\\nrecurrent_state shape: {first_layer['recurrent_state'].shape}\")\n",
        "    print(f\"recurrent_state dtype: {first_layer['recurrent_state'].dtype}\")\n",
        "    \n",
        "print(f\"\\nAll available keys in first layer:\")\n",
        "for key, value in first_layer.items():\n",
        "    if isinstance(value, torch.Tensor):\n",
        "        print(f\"  {key}: shape={value.shape}, dtype={value.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Extract States on Sample Input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with a simple sentence\n",
        "test_text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "print(f\"Input text: '{test_text}'\")\n",
        "print(f\"Input length: {len(test_text)} characters\")\n",
        "\n",
        "# Tokenize\n",
        "inputs = tokenizer(test_text, return_tensors=\"pt\")\n",
        "input_ids = inputs.input_ids.to(device)\n",
        "\n",
        "print(f\"Token IDs shape: {input_ids.shape}\")\n",
        "print(f\"Tokens: {tokenizer.convert_ids_to_tokens(input_ids[0])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract states incrementally at each token position\n",
        "# This gives us the KâŠ—V memory state after each token is processed\n",
        "print(\"\\nExtracting states incrementally...\")\n",
        "incremental_states = extractor.extract_states_incremental(input_ids)\n",
        "\n",
        "print(f\"\\n=== Incremental State Shapes ===\")\n",
        "print(f\"Number of positions: {len(incremental_states)}\")\n",
        "first_pos_states = incremental_states[1]\n",
        "print(f\"Number of layers per position: {len(first_pos_states)}\")\n",
        "print(f\"State shape at each position: {first_pos_states[0].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Verify State Shapes and Properties\n",
        "\n",
        "This section verifies that the extracted states have the expected dimensions and properties.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display state shapes for all layers\n",
        "print(\"\\n=== State Shapes ===\")\n",
        "for layer_idx in sorted(states.keys()):\n",
        "    state = states[layer_idx]\n",
        "    print(f\"Layer {layer_idx:2d}: shape={state.shape}, dtype={state.dtype}, device={state.device}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
